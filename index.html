<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yang Chen</title>

    <meta name="author" content="Yang Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yang Chen
                </p>
                <p>
		I am a Ph.D. student at Nanyang Technological University. My research interests revolve around 3D computer vision and deep learning.
                </p>
                <p style="text-align:center">
                  <a href="mailto:chen1605@e.ntu.edu.sg">Email</a> &nbsp;/&nbsp;
		  <a href="https://github.com/YangChenApril">Github</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=--XrFcIAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



		  
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
	      <img src='fig/BVN.png' width=100%>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
	<span class="papertitle">Boundary Voting Network for Ambiguity-aware Timestamp-supervised Action Segmentation
        </span>
        <br>
	      Runzhong Zhang, Yueqi Duan, <strong>Yang Chen</strong>, Weipeng Hu, Chen Cai, Suchen Wang, Yap-Peng Tan
	<br>
        <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2025 &nbsp
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/11007724">[PDF]</a>
        <p></p>
        <p>
	In this paper, we introduce the boundary voting network that mitigates feature ambiguity by hierarchically propagating video-level global prior knowledge into local action-transiting regions.
        </p>
      </td>
    </tr>
		  

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
	      <img src='fig/AMContrast3D.png' width=100%>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
	<span class="papertitle">Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation
        </span>
        <br>
	      <strong>Yang Chen</strong>, Yueqi Duan, Runzhong Zhang, Yap-Peng Tan
	<br>
        <em>IEEE International Conference on Multimedia and Expo (ICME)</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://ieeexplore.ieee.org/document/10688017?denied=">[PDF]</a>
        <a href="https://github.com/YangChenApril/AMContrast3D">[Code]</a>
        <p></p>
        <p>
	We propose an adaptive margin contrastive learning method for 3D point cloud semantic segmentation, namely AMContrast3D. We design adaptive objectives for individual points based on their ambiguity levels, aiming to ensure the correctness of low-ambiguity points while allowing mistakes for high-ambiguity points.
        </p>
      </td>
    </tr>









		  



		  
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src='images/Shelhamer2015.jpg'>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                  <span class="papertitle">Scene Intrinsics and Depth from a Single Image</span>
                </a>
                <br>
                <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV Workshop</em>, 2015
                <br>
                <a href="data/Shelhamer2015.bib">bibtex</a>
                <p></p>
                <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
              </td>
            </tr>




            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal">
                  <span class="papertitle">Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</span>
                </a>
                <br>
                <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>TPAMI</em>, 2017
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
                <p></p>
                <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
                <p>This paper subsumes our CVPR 2014 paper.</p>
              </td>
            </tr>

            

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                  <span class="papertitle">Multiscale Combinatorial Grouping</span>
                </a>
                <br>
                <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2014
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
              </td>
            </tr>

    

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/Boundary.jpg" alt="Boundary_png" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1H4YPovfrvcce3HGMEhidwU2l2fTcNR5y/view?usp=sharing">
                  <span class="papertitle">Boundary Cues for 3D Object Shape Recovery</span>
                </a>
                <br>
                <a href="http://www.kevinkarsch.com/">Kevin Karsch</a>,
                <a href="http://web.engr.illinois.edu/~liao17/">Zicheng Liao</a>,
                <a href="http://web.engr.illinois.edu/~jjrock2/">Jason Rock</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.illinois.edu/homes/dhoiem/">Derek Hoiem</a>
                <br>
                <em>CVPR</em>, 2013
                <br>
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmLUQ5SVJTcUZIYXc/view?usp=sharing">supplement</a> / <a href="data/KarschCVPR2013.bib">bibtex</a>
                <p>Boundary cues (like occlusions and folds) can be used for shape reconstruction, which improves object recognition for humans and computers.</p>
              </td>
            </tr>





        

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                  <span class="papertitle">A Category-Level 3-D Object Dataset: Putting the Kinect to Work</span>
                </a>
                <br>
                <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
                <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
                <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
                <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
                <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV 3DRR Workshop</em>, 2011
                <br>
                <a href="data/B3DO_ICCV_2011.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
                <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/safs.jpg" alt="safs_small" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                  <span class="papertitle">High-Frequency Shape and Albedo from Shading using Natural Image Statistics</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2011
                <br>
                <a href="data/BarronMalikCVPR2011.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/fast_texture.jpg" alt="fast-texture" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing">
                  <span class="papertitle">Discovering Efficiency in Coarse-To-Fine Texture Classification</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>Technical Report</em>, 2010
                <br>
                <a href="data/BarronTR2010.bib">bibtex</a>
                <p>A model and feature representation that allows for sub-linear coarse-to-fine semantic segmentation.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/prl.jpg" alt="prl" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <span class="papertitle">Parallelizing Reinforcement Learning</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                <br>
                <em>Technical Report</em>, 2009
                <br>
                <a href="data/BarronPRL2009.bib">bibtex</a>
                <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 136, 2008
                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
